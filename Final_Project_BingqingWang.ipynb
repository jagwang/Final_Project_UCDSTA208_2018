{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the Machine Help Understand the Human Responses\n",
    "\n",
    "## Bingqing Wang, 913473517\n",
    "\n",
    "## Final Project STA 208\n",
    "\n",
    "\n",
    "Social scientific studies often times involve human coders to read open-ended responses and code each response with numbers, so that follow-up statistical analysis can be employed. This type of method usually suffers several disadvantages.\n",
    "    \n",
    "  1. Human coders can suffer fatigue and inrealiability issues, which may result in unreliable coding for further analysis.\n",
    "  2. Human coders are usually cost inefficient and are harder to find compared to computers. \n",
    "    \n",
    "The present project aims at using machine learning technique to code textual responses. With minimal input and guidance, a machine can code the textual responses within seconds and with no fatigue and high reliability. The entire project consists of three part and two datasets I have collected in previous studies. \n",
    "    \n",
    "First, I will employ the first dataset to test the LDA (Latent Dirichlet Allocation) method in abstracting topics from open-ended responses. The first step is to ensure that meaningful different topics can be recognized by the machine and there are distinctive different topics in the dataset. This is an insurance policy to make sure that scholars are makign meaningful inference and usage with the programming.\n",
    "    \n",
    "Second, I will use the second dataset to let machines do human coding. I will use existed topics summaires to guide the program do the coding. These topics summaries were usually easily available when people train human coders to code texts. They can be definitions of a concept, category distinctions, as well as coding rubrics. In this step, I will have a basic coding program to do human coding jobs.\n",
    "    \n",
    "Third, I will improve the program so that it can fit various demands in social scientific studies. Due to the complexity of human behavious, social scientific studies usually have different specific demands in differnt areas. For example, people may declare several meanings in one responses. The last step is to improve the program to adapt to different environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I. Topic Modeling with LDA\n",
    "\n",
    "In the first part, LDA method is enployed to abstract topics from participants' responses. The dataset is from a study I have done about video game playing in families and the open-ended question asked the participants:\" Based on your expeiriences, what changes does video game bring to your families.\" I employed human coders to code these responses into three catrgories: social hedonic and eudaimonic fucnitons. The program below will try to extract these three topics from the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Based on your experiences, what changes does video game bring to your families?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it gives us a chance to spend time together at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It brings a greater sense of bonding, and we c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing.  just something to do.  not different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we can get together and play and have fun and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it makes us be more competitive with each othe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Based on your experiences, what changes does video game bring to your families?\n",
       "0  it gives us a chance to spend time together at...                             \n",
       "1  It brings a greater sense of bonding, and we c...                             \n",
       "2  nothing.  just something to do.  not different...                             \n",
       "3  we can get together and play and have fun and ...                             \n",
       "4  it makes us be more competitive with each othe...                             "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corp1 = pd.read_csv(\"C:\\\\Users\\\\jagwa\\\\Google Drive\\\\courses\\\\at UCD\\\\STA\\STA 208 ML\\\\project\\\\corpus1.csv\")\n",
    "corp1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Based on your experiences, what changes does video game bring to your families?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>In leisure time we spend by playing games and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Based on your experiences, what changes does video game bring to your families?\n",
       "count                                                 364                             \n",
       "unique                                                357                             \n",
       "top     In leisure time we spend by playing games and ...                             \n",
       "freq                                                    6                             "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it gives us a chance to spend time together at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It brings a greater sense of bonding, and we c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothing.  just something to do.  not different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we can get together and play and have fun and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it makes us be more competitive with each othe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 EXP\n",
       "0  it gives us a chance to spend time together at...\n",
       "1  It brings a greater sense of bonding, and we c...\n",
       "2  nothing.  just something to do.  not different...\n",
       "3  we can get together and play and have fun and ...\n",
       "4  it makes us be more competitive with each othe..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp1 = corp1.drop_duplicates(keep=\"first\")\n",
    "# complete documents\n",
    "doc_complete = corp1\n",
    "corp1.columns = [\"EXP\"]\n",
    "\n",
    "corp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_complete = doc_complete.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_complete = [str(i) for i in doc_complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exp', 'gives', 'us', 'chance', 'spend', 'time', 'together', 'brings', 'greater', 'sense', 'bonding', 'c', 'nothing', 'something', 'different', 'get', 'together', 'play', 'fun', 'makes', 'us', 'competitive', 'othe', 'let', 'us', 'competitive', 'together', 'helps', 'something', 'everyone', 'enjoys', 'brings', 'us', 'makes', 'us', 'closer', 'together', 'commonality', 'fun', 'gives', 'us', 'something', 'sort', 'excitement', 'whille', 'playing', 'video', 'brings', 'sort', 'relief', 'happiness', 'brings', 'us', 'closer', 'together', 'able', 'ta', 'fun', 'activity', 'alll', 'agree', 'give', 'us', 'activity', 'enjoy', 'together', 'something', 'together', 'also', 'shoo', 'helps', 'us', 'bond', 'together', 'fun', 'acti', 'happy', 'satisfaction', 'children', 'gives', 'us', 'something', 'together', 'c', 'son', 'loves', 'play', 'gets', 'kick', 'feel', 'refreshed', 'relaxed', 'good', 'way', 'nt', 'really', 'change', 'anything', 'one', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# understand the corpus\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(str(corp1))\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "# remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in doc_complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagwa\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.056*\"u\" + 0.046*\"it\" + 0.042*\"together\"'), (1, '0.031*\"game\" + 0.018*\"video\" + 0.015*\"time\"'), (2, '0.034*\"game\" + 0.022*\"video\" + 0.018*\"play\"')]\n"
     ]
    }
   ],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)\n",
    "\n",
    "print(ldamodel.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II. Improve the topic modeling\n",
    "\n",
    "In this part, I will try to improve the topic modeling results using various strategies. Mainly, the goal is to find a optimal number of topics in a specific corpus. In the previous part, I suspect there are three topics in the corpus, but the number is by no means determined. In traditional social science studies, there are usually two ways of determining the number of topics researchers would like to code. First, reserchers can look up the theory and see how many topics theories suggest. Second, people can look at first few responses and have a brief understanding about how many topics there are in the corpus. Both of these techniques have serious disadvangtages. Theories and practices can be far away from each other and using theory to guide the coding does little in improving the theory. The first few responses can be vary biased and far from accuracy. Thus, using machining learing to help determine the number of topics can be a very beneficial tool in social science studies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the same dataset from the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the meanings of words, synonyms, antonyms, and more. In addition, we use WordNetLemmatizer to get the root word.\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter stop words\n",
    "# nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allow', 'together', 'develop', 'experience']\n",
      "[]\n",
      "[]\n",
      "['think', 'bring', 'cooperation', 'communication', 'sense', 'accomplishment', 'depend', 'increase', 'daughter', 'dexterity', 'help', 'teach', 'solve', 'problem']\n",
      "['together', 'something', 'enjoy', 'change', 'positive']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['help', 'inside', 'joke', 'saying', 'game', 'keep', 'connect', 'interest']\n",
      "['helping', 'improve', 'decision', 'making', 'power']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "text_data = []\n",
    "with open(\"C:\\\\Users\\\\jagwa\\\\Google Drive\\\\courses\\\\at UCD\\\\STA\\STA 208 ML\\\\project\\\\corpus1.csv\") as f:\n",
    "    for line in f:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        if random.random() > .99:\n",
    "            print(tokens)\n",
    "            text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.053*\"help\" + 0.053*\"think\" + 0.053*\"cooperation\" + 0.053*\"dexterity\"')\n",
      "(1, '0.055*\"saying\" + 0.055*\"keep\" + 0.055*\"connect\" + 0.055*\"game\"')\n",
      "(2, '0.115*\"together\" + 0.066*\"something\" + 0.066*\"change\" + 0.066*\"positive\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 3\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model3.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the results to code a new statement into one of the three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 1), (23, 1)]\n",
      "[(0, 0.11222827), (1, 0.42873764), (2, 0.45903412)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = 'I like video games that make us bonding together.'\n",
    "new_doc = prepare_text_for_lda(new_doc)\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "print(new_doc_bow)\n",
    "print(ldamodel.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.082*\"decision\" + 0.082*\"making\" + 0.082*\"helping\" + 0.082*\"power\"')\n",
      "(1, '0.082*\"together\" + 0.047*\"interest\" + 0.047*\"saying\" + 0.047*\"connect\"')\n",
      "(2, '0.053*\"help\" + 0.053*\"daughter\" + 0.053*\"cooperation\" + 0.053*\"accomplishment\"')\n"
     ]
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 3, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model3.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagwa\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el560017477406838645443428528\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el560017477406838645443428528_data = {\"mdsDat\": {\"Freq\": [15.574989766717776, 44.14252347901666, 40.28248675426556], \"cluster\": [1, 1, 1], \"topics\": [1, 2, 3], \"x\": [0.004096285152405608, -0.08992214926053702, 0.08582586410813141], \"y\": [-0.062497080304726275, 0.02906354365754706, 0.033433536647179185]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4571440616579037, 0.4571429754981106, 0.45713917393883474, 0.45713858908356153, 0.4571385473081849, 0.11470569084838168, 0.11470445847477027, 0.1147038318441204, 0.11463232284312616, 0.11463122623948889, 0.11462803042317456, 0.11462791554088875, 0.1145532316112685, 0.11454417679837789, 0.11454388437074128, 0.11454385303920879, 0.11454161805655759, 0.11453481911400651, 0.11453401493800584, 0.11442971226633511, 0.11442936761947768, 0.1144288036518928, 0.11442820835277542, 0.11442799947589213, 0.11442767571672303, 0.11442761305365805, 0.1144273310698656, 0.11442712219298232, 0.11442687154072237, 0.11442652689386494, 0.1146573985129651, 0.11464773795711294, 1.3087606359448711, 0.7478403017852355, 0.7478356250061418, 0.747823785059069, 0.7478214170696544, 0.7478197594770642, 0.7478166810908253, 0.7478034203501038, 0.7475830197353442, 0.7475826645369321, 0.7475659110118241, 0.7475633654232035, 0.7473748142660697, 0.7473733934724209, 0.747372268677449, 0.7457743494205084, 0.18725170814264497, 0.18725068694720992, 0.18724882215554597, 0.18724805255898624, 0.18724606936785154, 0.18718410204485947, 0.18718368764671192, 0.18718337684810127, 0.18718248885207078, 0.18718139365696657, 0.18718040206139921, 0.18718035766159768, 0.18717998766325167, 0.1871793808659642, 0.18717954366523645, 0.7627915232106847, 0.7627915772337075, 0.7627903347041814, 0.7627897404509298, 0.7627894703358155, 0.7627889301055867, 0.7627885519444265, 0.7627869852767631, 0.7627866071156031, 0.7627835278032992, 0.7627832576881848, 0.7627816910205215, 0.7627803944679725, 0.7651517890800762, 0.19093966084154645, 0.19093886400195906, 0.19093770250696726, 0.19093438009106045, 0.19093413698745754, 0.19115437534596158, 0.19115428080567154, 0.19114976988326152, 0.19108170087443951, 0.1910772844923195, 0.19106734425611058, 0.19106718218704197, 0.19096913040052454, 0.19096710453716675, 0.1909661186169993, 0.1909656864328163, 0.19096629419182365, 0.19111510060833173, 0.19096378212125997, 0.19096016257872736], \"Term\": [\"decision\", \"making\", \"helping\", \"power\", \"improve\", \"together\", \"dexterity\", \"accomplishment\", \"cooperation\", \"problem\", \"daughter\", \"depend\", \"communication\", \"bring\", \"teach\", \"sense\", \"think\", \"solve\", \"increase\", \"keep\", \"inside\", \"interest\", \"game\", \"connect\", \"joke\", \"saying\", \"change\", \"enjoy\", \"something\", \"positive\", \"decision\", \"making\", \"helping\", \"power\", \"improve\", \"allow\", \"develop\", \"experience\", \"something\", \"positive\", \"enjoy\", \"change\", \"keep\", \"inside\", \"joke\", \"game\", \"connect\", \"interest\", \"saying\", \"increase\", \"think\", \"sense\", \"solve\", \"communication\", \"problem\", \"teach\", \"dexterity\", \"depend\", \"accomplishment\", \"bring\", \"together\", \"help\", \"together\", \"interest\", \"saying\", \"connect\", \"inside\", \"game\", \"joke\", \"keep\", \"change\", \"enjoy\", \"something\", \"positive\", \"allow\", \"experience\", \"develop\", \"help\", \"power\", \"improve\", \"helping\", \"making\", \"decision\", \"increase\", \"solve\", \"think\", \"sense\", \"teach\", \"communication\", \"bring\", \"depend\", \"problem\", \"daughter\", \"cooperation\", \"daughter\", \"accomplishment\", \"dexterity\", \"bring\", \"depend\", \"problem\", \"communication\", \"teach\", \"sense\", \"solve\", \"think\", \"increase\", \"help\", \"helping\", \"improve\", \"power\", \"decision\", \"making\", \"develop\", \"experience\", \"allow\", \"positive\", \"something\", \"enjoy\", \"change\", \"joke\", \"keep\", \"game\", \"connect\", \"saying\", \"together\", \"inside\", \"interest\"], \"Total\": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8353245111168157, 0.8353251650445543, 0.8353276569359271, 0.8353279997331738, 0.8353280982573538, 1.053230274997713, 1.0532311024981809, 1.0532315061222128, 1.0532755183472697, 1.0532762925371317, 1.0532780392162173, 1.053278117463275, 1.0533237564985392, 1.0533293759892923, 1.0533296958620912, 1.0533297311332723, 1.053331089548443, 1.0533352834779695, 1.0533359341359714, 1.0643942087791671, 1.0643944354881005, 1.0643948203072626, 1.0643951536876721, 1.0643953868140545, 1.0643956085271138, 1.0643956138262278, 1.0643958751893399, 1.0643960399618206, 1.0643961579127867, 1.064396354891278, 1.614533135066168, 1.6255738764576975, 1.614533135066168, 1.0533352834779695, 1.0533359341359714, 1.053331089548443, 1.0533293759892923, 1.0533297311332723, 1.0533296958620912, 1.0533237564985392, 1.053278117463275, 1.0532780392162173, 1.0532755183472697, 1.0532762925371317, 1.053230274997713, 1.0532315061222128, 1.0532311024981809, 1.6255738764576975, 0.8353279997331738, 0.8353280982573538, 0.8353276569359271, 0.8353251650445543, 0.8353245111168157, 1.0643942087791671, 1.0643951536876721, 1.0643944354881005, 1.0643948203072626, 1.0643956138262278, 1.0643953868140545, 1.064396354891278, 1.0643960399618206, 1.0643956085271138, 1.0643968749483408, 1.0643967564228776, 1.0643968749483408, 1.0643961579127867, 1.0643958751893399, 1.064396354891278, 1.0643960399618206, 1.0643956085271138, 1.0643953868140545, 1.0643956138262278, 1.0643948203072626, 1.0643951536876721, 1.0643944354881005, 1.0643942087791671, 1.6255738764576975, 0.8353276569359271, 0.8353280982573538, 0.8353279997331738, 0.8353245111168157, 0.8353251650445543, 1.0532311024981809, 1.0532315061222128, 1.053230274997713, 1.0532762925371317, 1.0532755183472697, 1.0532780392162173, 1.053278117463275, 1.0533296958620912, 1.0533237564985392, 1.0533297311332723, 1.053331089548443, 1.0533359341359714, 1.614533135066168, 1.0533293759892923, 1.0533352834779695], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2567, 1.2567, 1.2567, 1.2567, 1.2567, -0.3577, -0.3578, -0.3578, -0.3584, -0.3584, -0.3585, -0.3585, -0.3592, -0.3592, -0.3592, -0.3593, -0.3593, -0.3593, -0.3593, -0.3707, -0.3707, -0.3707, -0.3707, -0.3707, -0.3707, -0.3707, -0.3707, -0.3707, -0.3707, -0.3707, -0.7853, -0.7922, 0.6078, 0.4752, 0.4752, 0.4752, 0.4752, 0.4752, 0.4752, 0.4752, 0.4749, 0.4749, 0.4749, 0.4749, 0.4747, 0.4747, 0.4747, 0.0386, -0.6776, -0.6776, -0.6776, -0.6776, -0.6777, -0.9203, -0.9203, -0.9203, -0.9203, -0.9203, -0.9203, -0.9203, -0.9203, -0.9203, -0.9203, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.5761, 0.1557, -0.5666, -0.5666, -0.5666, -0.5666, -0.5666, -0.7973, -0.7973, -0.7973, -0.7977, -0.7977, -0.7978, -0.7978, -0.7983, -0.7984, -0.7984, -0.7984, -0.7984, -1.2247, -0.7984, -0.7984], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.5067999362945557, -2.5067999362945557, -2.5067999362945557, -2.5067999362945557, -2.5067999362945557, -3.889400005340576, -3.889400005340576, -3.889400005340576, -3.890000104904175, -3.890000104904175, -3.8901000022888184, -3.8901000022888184, -3.890700101852417, -3.8907999992370605, -3.8907999992370605, -3.8907999992370605, -3.8907999992370605, -3.890899896621704, -3.890899896621704, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8917999267578125, -3.8898000717163086, -3.889899969100952, -2.4967000484466553, -3.056299924850464, -3.056299924850464, -3.0564000606536865, -3.0564000606536865, -3.0564000606536865, -3.0564000606536865, -3.0564000606536865, -3.0566999912261963, -3.0566999912261963, -3.0566999912261963, -3.0566999912261963, -3.056999921798706, -3.056999921798706, -3.056999921798706, -3.0590999126434326, -4.441100120544434, -4.441100120544434, -4.441100120544434, -4.441100120544434, -4.441100120544434, -4.441400051116943, -4.441400051116943, -4.441400051116943, -4.441400051116943, -4.441400051116943, -4.441500186920166, -4.441500186920166, -4.441500186920166, -4.441500186920166, -4.441500186920166, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.944999933242798, -2.9451000690460205, -2.9419000148773193, -4.330100059509277, -4.330100059509277, -4.330100059509277, -4.330100059509277, -4.330100059509277, -4.32889986038208, -4.32889986038208, -4.328999996185303, -4.3292999267578125, -4.3292999267578125, -4.329400062561035, -4.329400062561035, -4.329899787902832, -4.329899787902832, -4.329899787902832, -4.329899787902832, -4.329899787902832, -4.329100131988525, -4.329899787902832, -4.329999923706055]}, \"token.table\": {\"Topic\": [3, 2, 3, 2, 3, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 3, 3, 2, 3, 3, 2], \"Freq\": [0.9394998211576943, 0.9494599839547638, 0.9394996472927082, 0.9494168571624838, 0.9395005017761279, 0.949369110930443, 0.939499292877126, 0.9394991882595801, 0.9394999252682954, 0.949459237984977, 0.9395000707064138, 0.9494169276937897, 0.9494588741290122, 0.9493703352739363, 0.6151673661114122, 0.6151673661114122, 0.9395015415829576, 0.9493706553667459, 0.9493653309496445, 0.9493703670639952, 0.9493757202668645, 0.9494185021398328, 0.9395003060786553, 0.9493647445155076, 0.9395010018099548, 0.9395007075477838, 0.9494191999915975, 0.939500301401335, 0.9395013414753798, 0.6193740953845567], \"Term\": [\"accomplishment\", \"allow\", \"bring\", \"change\", \"communication\", \"connect\", \"cooperation\", \"daughter\", \"depend\", \"develop\", \"dexterity\", \"enjoy\", \"experience\", \"game\", \"help\", \"help\", \"increase\", \"inside\", \"interest\", \"joke\", \"keep\", \"positive\", \"problem\", \"saying\", \"sense\", \"solve\", \"something\", \"teach\", \"think\", \"together\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el560017477406838645443428528\", ldavis_el560017477406838645443428528_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el560017477406838645443428528\", ldavis_el560017477406838645443428528_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el560017477406838645443428528\", ldavis_el560017477406838645443428528_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing 3 topics\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model3.gensim')\n",
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the graph above, it can be seen that topic one, whatever that topic is, is pretty insignificant in the corpus. This suggest that three topics do not fit the reponses, even though in theory, there should be three topics in the responses. Next, i will try two topics and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.038*\"help\" + 0.038*\"dexterity\" + 0.038*\"think\" + 0.038*\"accomplishment\"')\n",
      "(1, '0.052*\"together\" + 0.050*\"help\" + 0.050*\"joke\" + 0.050*\"game\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 2\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model2.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.058*\"help\" + 0.035*\"bring\" + 0.035*\"teach\" + 0.035*\"dexterity\" + 0.035*\"increase\"')\n",
      "(1, '0.059*\"together\" + 0.055*\"decision\" + 0.055*\"power\" + 0.055*\"helping\" + 0.055*\"positive\"')\n"
     ]
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 2, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model2.gensim')\n",
    "topics = ldamodel.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagwa\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el560017477360782806213301832\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el560017477360782806213301832_data = {\"mdsDat\": {\"Freq\": [70.44581409612314, 29.554185903876856], \"cluster\": [1, 1], \"topics\": [1, 2], \"x\": [0.05241458863019943, -0.05241458863019943], \"y\": [0.0, 0.0]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4784194333727743, 0.8871283549903006, 0.887010922317809, 0.8869912714763944, 0.886956882503919, 0.8869485686863975, 0.8869309018241642, 0.886925422262616, 0.8868868763813798, 0.8868831918486145, 0.8868718548247215, 0.886835670823463, 0.8868309470635076, 0.8867251348405063, 0.886022806210335, 0.8859762299371746, 0.8859606415293217, 0.8859522332366011, 0.8859415575391019, 0.8859247409536606, 0.8858593641158776, 0.8790618735400337, 0.8788613026923268, 0.8787617258324666, 0.829398906674363, 0.2983555366588593, 0.29833690142583513, 0.29828980553907963, 0.2982758232096116, 0.2982675566296896, 0.5853733942826916, 0.5853339572068992, 0.5853260301564887, 0.5853129108880593, 0.5853088680923499, 0.5853033587923147, 0.5852941634138384, 0.5852630893762292, 0.5852508024480928, 0.625886963520817, 0.20224666192561808, 0.20218092686008876, 0.202048584753485, 0.19756298400818376, 0.19751984103632447, 0.1975088026186278, 0.19750166827325832, 0.197496158973223, 0.19748585380768932, 0.19745511666972249, 0.19699168148509702, 0.19692190362385836, 0.19691875262132016, 0.19689483274670638, 0.1968873813193205, 0.19688500320419733, 0.19685949791950147, 0.1968559109291907, 0.1968442383474612, 0.19683880831793, 0.19760499737535955], \"Term\": [\"decision\", \"power\", \"helping\", \"positive\", \"improve\", \"making\", \"something\", \"change\", \"enjoy\", \"together\", \"help\", \"develop\", \"experience\", \"allow\", \"saying\", \"inside\", \"game\", \"keep\", \"connect\", \"joke\", \"interest\", \"solve\", \"daughter\", \"sense\", \"communication\", \"think\", \"problem\", \"depend\", \"accomplishment\", \"cooperation\", \"help\", \"bring\", \"teach\", \"dexterity\", \"increase\", \"cooperation\", \"accomplishment\", \"depend\", \"problem\", \"think\", \"communication\", \"sense\", \"daughter\", \"solve\", \"interest\", \"joke\", \"connect\", \"keep\", \"game\", \"inside\", \"saying\", \"allow\", \"experience\", \"develop\", \"together\", \"enjoy\", \"change\", \"something\", \"making\", \"improve\", \"decision\", \"power\", \"helping\", \"positive\", \"improve\", \"making\", \"something\", \"change\", \"enjoy\", \"together\", \"develop\", \"experience\", \"allow\", \"saying\", \"inside\", \"game\", \"keep\", \"connect\", \"joke\", \"interest\", \"solve\", \"daughter\", \"sense\", \"communication\", \"think\", \"problem\", \"depend\", \"accomplishment\", \"cooperation\", \"increase\", \"help\"], \"Total\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.6760244307481338, 1.0838539452107423, 1.0838140589088916, 1.0838073687948984, 1.083795690821849, 1.0837928070338587, 1.083786812753355, 1.0837849201821175, 1.083771879585577, 1.083770573167935, 1.083766687571428, 1.0837544234447831, 1.083752850687366, 1.0837168163256032, 1.0834779228800575, 1.0834620837448639, 1.0834568005025447, 1.0834539015098594, 1.0834503601577297, 1.0834445819899852, 1.0834223481240615, 1.0811104582935187, 1.0810422295524156, 1.0810083877580847, 1.4552858701951799, 0.8836063391069521, 0.8835999908020643, 0.8835839689529181, 0.8835791820019263, 0.8835764247220396, 0.8835431454625043, 0.8835635820441468, 0.8835676297252233, 0.8835743266298068, 0.8835764247220396, 0.8835791820019263, 0.8835839689529181, 0.8835999908020643, 0.8836063391069521, 1.4552858701951799, 1.0810083877580847, 1.0810422295524156, 1.0811104582935187, 1.0834223481240615, 1.0834445819899852, 1.0834503601577297, 1.0834539015098594, 1.0834568005025447, 1.0834620837448639, 1.0834779228800575, 1.0837168163256032, 1.083752850687366, 1.0837544234447831, 1.083766687571428, 1.083770573167935, 1.083771879585577, 1.0837849201821175, 1.083786812753355, 1.0837928070338587, 1.083795690821849, 1.6760244307481338], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.2249, 0.15, 0.1499, 0.1499, 0.1499, 0.1499, 0.1499, 0.1499, 0.1498, 0.1498, 0.1498, 0.1498, 0.1498, 0.1497, 0.1491, 0.1491, 0.1491, 0.1491, 0.1491, 0.1491, 0.149, 0.1434, 0.1433, 0.1432, -0.2119, -0.7354, -0.7355, -0.7356, -0.7356, -0.7357, 0.8073, 0.8072, 0.8071, 0.8071, 0.8071, 0.8071, 0.8071, 0.807, 0.807, 0.3752, -0.4572, -0.4576, -0.4583, -0.4829, -0.4831, -0.4832, -0.4832, -0.4832, -0.4833, -0.4835, -0.486, -0.4864, -0.4865, -0.4866, -0.4866, -0.4866, -0.4868, -0.4868, -0.4869, -0.4869, -0.919], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.8422000408172607, -3.3529999256134033, -3.353100061416626, -3.353100061416626, -3.3531999588012695, -3.3531999588012695, -3.3531999588012695, -3.3531999588012695, -3.3531999588012695, -3.3531999588012695, -3.3531999588012695, -3.353300094604492, -3.353300094604492, -3.3533999919891357, -3.3541998863220215, -3.354300022125244, -3.354300022125244, -3.354300022125244, -3.354300022125244, -3.354300022125244, -3.3543999195098877, -3.3620998859405518, -3.362299919128418, -3.3624000549316406, -3.4202001094818115, -4.442699909210205, -4.442699909210205, -4.44290018081665, -4.44290018081665, -4.442999839782715, -2.900099992752075, -2.900099992752075, -2.9001998901367188, -2.9001998901367188, -2.9001998901367188, -2.9001998901367188, -2.9001998901367188, -2.9003000259399414, -2.9003000259399414, -2.833199977874756, -3.9628000259399414, -3.963200092315674, -3.9637999534606934, -3.986299991607666, -3.9865000247955322, -3.9865000247955322, -3.986599922180176, -3.986599922180176, -3.9867000579833984, -3.986799955368042, -3.9892001152038574, -3.989500045776367, -3.989500045776367, -3.9897000789642334, -3.9897000789642334, -3.9897000789642334, -3.989799976348877, -3.9899001121520996, -3.9899001121520996, -3.9899001121520996, -3.9860999584198]}, \"token.table\": {\"Topic\": [1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2], \"Freq\": [0.9226906880879137, 0.9249748648056298, 0.9226335378661763, 1.1317338279873415, 0.9227078221428473, 0.9229717322704195, 0.9226855848368433, 0.9227196028741738, 1.1318066414023669, 0.9226922993465914, 0.9250622024070609, 0.9226731878672453, 1.1317256970006409, 0.9250332435339094, 0.9229772186834837, 0.5966500139581056, 1.1317752782670247, 1.1317640127333475, 0.9226831297342527, 0.9229821410554098, 0.9229537389574494, 0.9229672316207074, 0.9229742018616931, 1.1317604809727397, 1.1317667001646283, 1.1317804630273178, 0.9227034017365254, 0.9230010823862858, 0.9227182638124195, 0.9227502839630658, 1.1317543494876208, 0.9226674924356769, 0.9227045139977662, 0.6871502159681397, 0.6871502159681397], \"Term\": [\"accomplishment\", \"allow\", \"bring\", \"change\", \"communication\", \"connect\", \"cooperation\", \"daughter\", \"decision\", \"depend\", \"develop\", \"dexterity\", \"enjoy\", \"experience\", \"game\", \"help\", \"helping\", \"improve\", \"increase\", \"inside\", \"interest\", \"joke\", \"keep\", \"making\", \"positive\", \"power\", \"problem\", \"saying\", \"sense\", \"solve\", \"something\", \"teach\", \"think\", \"together\", \"together\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el560017477360782806213301832\", ldavis_el560017477360782806213301832_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el560017477360782806213301832\", ldavis_el560017477360782806213301832_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el560017477360782806213301832\", ldavis_el560017477360782806213301832_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model2.gensim')\n",
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the interactive graph above, it can be seen that the two topics are about the same size, and although ther are a lot of overlaps betwee nthe two topics, some distinctions can be made to distinguish the two topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Analysis of the first corpus_  \n",
    "From the results above, it can be seen that there are two main topics in the resopnses. First, people enjoy playing video games and believe it is \"something\" in the families. Second, from the responses, it is clear that video games have the bonding effect in family settings, family members share activities and feel something in \"common\". Therefore, we can interpret the responses and answer the question \"what do video games bring to families\" like the following:  \n",
    "Video games mainly have two functions in the family settings. First, it provides hedonism/fun to family members so that they have something to enjoy. Second, video games have social/relatedness fucntion to families, so that family members have something in common and they are be bonded together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III. Applying the same technique to another dataset  \n",
    "In part III, I will apply the same technique to another dataset that is newly collected. The new corpus comes from another study that investigates people's experience in consuming movies. The question asks the participants: Based on your experience, what does watching movies bring to your life. The question is open-ended, and there is no previous human coding on this corpus. In this part, I will apply the same technique and see how many topics I can extract from the responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:1: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:1: DeprecationWarning: invalid escape sequence \\S\n",
      "<ipython-input-40-91f68b74ffd2>:1: DeprecationWarning: invalid escape sequence \\S\n",
      "  corp2 = pd.read_csv(\"C:\\\\Users\\\\jagwa\\\\Google Drive\\\\courses\\\\at UCD\\\\STA\\STA 208 ML\\\\project\\\\corpus2.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's a nice way to get away from real life and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie are based on the my life and very modera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entertainment. Diversion. A distraction from d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it brings enjoyment and give me a view on how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It arouses my imagination. It depends on what ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Movie experience\n",
       "0  It's a nice way to get away from real life and...\n",
       "1  movie are based on the my life and very modera...\n",
       "2  Entertainment. Diversion. A distraction from d...\n",
       "3  it brings enjoyment and give me a view on how ...\n",
       "4  It arouses my imagination. It depends on what ..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp2 = pd.read_csv(\"C:\\\\Users\\\\jagwa\\\\Google Drive\\\\courses\\\\at UCD\\\\STA\\STA 208 ML\\\\project\\\\corpus2.csv\")\n",
    "corp2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>The best movies make you think while entertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Movie experience\n",
       "count                                                 359\n",
       "unique                                                352\n",
       "top     The best movies make you think while entertain...\n",
       "freq                                                    3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<input>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "<ipython-input-34-36acebcf87a6>:2: DeprecationWarning: invalid escape sequence \\S\n",
      "  with open(\"C:\\\\Users\\\\jagwa\\\\Google Drive\\\\courses\\\\at UCD\\\\STA\\STA 208 ML\\\\project\\\\corpus2.csv\") as f:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entertainment']\n",
      "['allow', 'experience', 'situation', 'otherwise', 'would', 'never', 'opportunity', 'experience', 'allow', 'range', 'emotion', 'short', 'period', 'without', 'emotion', 'hurting', 'movie', 'bring', 'richness', 'variety', 'depth', 'screen']\n",
      "['think', 'provide', 'decent', 'entertainment', 'movie', 'general', 'science', 'fiction']\n",
      "[]\n",
      "['offer', 'chance', 'escape', 'forget', 'worry', 'responsibility', 'hours']\n",
      "['give', 'happiness']\n",
      "['help', 'relax', 'forget', 'problem', 'inspire']\n",
      "['movie', 'awarnes', 'socity', 'movie.all', 'people', 'please', 'watch', 'movie']\n"
     ]
    }
   ],
   "source": [
    "text_data_2 = []\n",
    "with open(\"C:\\\\Users\\\\jagwa\\\\Google Drive\\\\courses\\\\at UCD\\\\STA\\STA 208 ML\\\\project\\\\corpus2.csv\") as f:\n",
    "    for line in f:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        if random.random() > .99:\n",
    "            print(tokens)\n",
    "            text_data_2.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data_2)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data_2]\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.081*\"movie\" + 0.046*\"socity\" + 0.046*\"movie.all\" + 0.046*\"awarnes\"')\n",
      "(1, '0.052*\"emotion\" + 0.052*\"allow\" + 0.052*\"experience\" + 0.052*\"movie\"')\n",
      "(2, '0.056*\"forget\" + 0.055*\"offer\" + 0.055*\"responsibility\" + 0.055*\"worry\"')\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 3\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model3_2.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.061*\"forget\" + 0.061*\"help\" + 0.061*\"inspire\" + 0.061*\"relax\"')\n",
      "(1, '0.074*\"movie\" + 0.052*\"experience\" + 0.052*\"allow\" + 0.052*\"emotion\"')\n",
      "(2, '0.075*\"entertainment\" + 0.043*\"think\" + 0.043*\"science\" + 0.043*\"general\"')\n"
     ]
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 3, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model3_2.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagwa\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el560017477412459923728035681\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el560017477412459923728035681_data = {\"mdsDat\": {\"Freq\": [13.92969219972584, 56.649286211833605, 29.42102158844055], \"cluster\": [1, 1, 1], \"topics\": [1, 2, 3], \"x\": [0.018722868240519504, -0.09848972144561315, 0.07976685320509366], \"y\": [-0.06130172234454867, 0.020992782030260407, 0.04030894031428825]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4469419891106108, 0.4469406139687201, 0.4469386062615598, 0.4469237822319787, 0.4466263115381963, 0.44662391879130664, 0.44826218033129694, 0.1119731355477735, 0.11197149912892365, 0.1119707290494649, 0.11197060528669472, 0.11196915451200011, 0.11196707804774525, 0.11193410902091724, 0.11193175752828427, 0.11193160626267629, 0.11193081555608918, 0.11193046489490707, 0.11192924101862439, 0.11199972391622895, 0.11199787435038605, 0.1119974686835283, 0.11199540597069235, 0.11199427147863258, 0.11199327450076187, 0.11186314482365098, 0.1118624641284151, 0.11186197595304394, 0.11186142589628768, 0.11186207221297628, 0.11186221660287479, 0.11186356424192762, 0.11186235411706386, 0.11186257413976636, 0.11248893064382272, 0.11209304792063696, 1.5563815535727028, 1.556345873879381, 1.5562201560884914, 0.8894247373100237, 0.8893748528485141, 0.8893645068559365, 0.8893154053344058, 0.8893108195431011, 0.8892809559753364, 0.8892798374896523, 0.8892793900953787, 0.8892499739218876, 0.8892259824039643, 0.8892164752756497, 0.8892012638703464, 0.8892009283246411, 0.8891877861178533, 0.889186611707885, 0.8889029637384047, 0.888891219638722, 0.8888769589462501, 0.8888546451568529, 0.8888378678715918, 0.8888058232567432, 2.228688310559429, 0.22290706648905284, 0.22290663307585026, 0.22266214608638346, 0.22264809510997732, 0.2226420692683544, 0.22327722932619604, 0.2228120930734042, 1.1719713892433978, 0.6703078294883618, 0.6703075390434713, 0.6703022529464648, 0.6703032404590924, 0.6703023110354429, 0.6702970830274146, 0.670250495666984, 0.6702457904597585, 0.6702441058793938, 0.6702435249896129, 0.6702435249896129, 0.6702355667996142, 0.6687219422974461, 0.6672397439324264, 0.1681251866250872, 0.16812128014131045, 0.1678597054729579, 0.16784961251301422, 0.1678480876773393, 0.16784800054387217, 0.16817599995867402, 0.1681614922363953, 0.1681456339453759, 0.16813054533331628, 0.16811502105392093, 0.16810559611722536, 0.16809640353644215, 0.16809288915326753, 0.16808478574082356, 0.1684019660834556, 0.16830636614775912, 0.16828025515210634, 0.168083827272685], \"Term\": [\"forget\", \"entertainment\", \"help\", \"inspire\", \"relax\", \"problem\", \"give\", \"happiness\", \"think\", \"decent\", \"science\", \"general\", \"fiction\", \"provide\", \"escape\", \"responsibility\", \"hours\", \"offer\", \"worry\", \"chance\", \"experience\", \"allow\", \"emotion\", \"watch\", \"awarnes\", \"please\", \"socity\", \"people\", \"movie.all\", \"screen\", \"help\", \"inspire\", \"relax\", \"problem\", \"give\", \"happiness\", \"forget\", \"chance\", \"responsibility\", \"hours\", \"worry\", \"offer\", \"escape\", \"decent\", \"fiction\", \"general\", \"think\", \"provide\", \"science\", \"people\", \"watch\", \"awarnes\", \"socity\", \"please\", \"movie.all\", \"range\", \"opportunity\", \"bring\", \"short\", \"never\", \"without\", \"otherwise\", \"richness\", \"situation\", \"entertainment\", \"movie\", \"experience\", \"allow\", \"emotion\", \"screen\", \"would\", \"depth\", \"otherwise\", \"hurting\", \"situation\", \"variety\", \"period\", \"richness\", \"without\", \"never\", \"opportunity\", \"bring\", \"range\", \"short\", \"watch\", \"awarnes\", \"please\", \"socity\", \"movie.all\", \"people\", \"movie\", \"give\", \"happiness\", \"problem\", \"relax\", \"inspire\", \"entertainment\", \"forget\", \"entertainment\", \"think\", \"science\", \"decent\", \"general\", \"fiction\", \"provide\", \"escape\", \"offer\", \"hours\", \"responsibility\", \"worry\", \"chance\", \"forget\", \"movie\", \"happiness\", \"give\", \"problem\", \"inspire\", \"help\", \"relax\", \"people\", \"movie.all\", \"socity\", \"please\", \"awarnes\", \"watch\", \"short\", \"range\", \"bring\", \"emotion\", \"allow\", \"experience\", \"opportunity\"], \"Total\": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8374313631163256, 0.8374322957500887, 0.8374347019154093, 0.8374456337913201, 0.8376546581685597, 0.8376557384922441, 1.3397962157021472, 1.0048579858484044, 1.0048569535761804, 1.0048575193643394, 1.0048579192164013, 1.0048585941011416, 1.0048590557780996, 1.0048748241194052, 1.004877130488126, 1.0048769299711942, 1.0048763522186375, 1.004880075031822, 1.0048780244472582, 1.1689815471316463, 1.169006434206016, 1.1690037093761712, 1.168995685072921, 1.1690017757581987, 1.168992634608749, 1.169143820094772, 1.1691475552714465, 1.1691476900185087, 1.1691444411406149, 1.1691514540334298, 1.169153757295914, 1.1691750679698534, 1.1691596899556387, 1.169167075550772, 1.5077375492134166, 3.008021102412492, 1.8365208625013354, 1.8365117476004902, 1.8364811003156691, 1.1692035705520405, 1.1691909865523962, 1.1691880282195473, 1.1691750679698534, 1.1691748373418032, 1.169167075550772, 1.1691670250206363, 1.1691668519456362, 1.1691596899556387, 1.169153757295914, 1.1691514540334298, 1.1691475552714465, 1.1691476900185087, 1.169143820094772, 1.1691444411406149, 1.169006434206016, 1.1690037093761712, 1.1690017757581987, 1.168995685072921, 1.168992634608749, 1.1689815471316463, 3.008021102412492, 0.8376546581685597, 0.8376557384922441, 0.8374456337913201, 0.8374347019154093, 0.8374322957500887, 1.5077375492134166, 1.3397962157021472, 1.5077375492134166, 1.0048763522186375, 1.0048780244472582, 1.0048748241194052, 1.0048769299711942, 1.004877130488126, 1.004880075031822, 1.0048590557780996, 1.0048585941011416, 1.0048575193643394, 1.0048569535761804, 1.0048579192164013, 1.0048579858484044, 1.3397962157021472, 3.008021102412492, 0.8376557384922441, 0.8376546581685597, 0.8374456337913201, 0.8374322957500887, 0.8374313631163256, 0.8374347019154093, 1.1689815471316463, 1.168992634608749, 1.168995685072921, 1.1690017757581987, 1.1690037093761712, 1.169006434206016, 1.1691444411406149, 1.169143820094772, 1.1691476900185087, 1.8364811003156691, 1.8365117476004902, 1.8365208625013354, 1.1691475552714465], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3432, 1.3432, 1.3432, 1.3432, 1.3423, 1.3423, 0.8763, -0.2232, -0.2232, -0.2232, -0.2232, -0.2232, -0.2233, -0.2236, -0.2236, -0.2236, -0.2236, -0.2236, -0.2236, -0.3742, -0.3743, -0.3743, -0.3743, -0.3743, -0.3743, -0.3756, -0.3756, -0.3756, -0.3756, -0.3756, -0.3756, -0.3756, -0.3756, -0.3756, -0.6244, -1.3186, 0.4028, 0.4028, 0.4027, 0.2948, 0.2947, 0.2947, 0.2947, 0.2947, 0.2947, 0.2947, 0.2947, 0.2946, 0.2946, 0.2946, 0.2946, 0.2946, 0.2946, 0.2946, 0.2944, 0.2944, 0.2943, 0.2943, 0.2943, 0.2943, 0.2684, -0.7556, -0.7556, -0.7564, -0.7565, -0.7565, -1.3417, -1.2257, 0.9715, 0.8186, 0.8186, 0.8186, 0.8186, 0.8186, 0.8186, 0.8185, 0.8185, 0.8185, 0.8185, 0.8185, 0.8185, 0.5286, -0.2824, -0.3824, -0.3825, -0.3838, -0.3838, -0.3838, -0.3838, -0.7154, -0.7155, -0.7156, -0.7157, -0.7158, -0.7159, -0.716, -0.716, -0.7161, -1.1658, -1.1664, -1.1665, -0.7161], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.804500102996826, -2.804500102996826, -2.804500102996826, -2.804500102996826, -2.8052000999450684, -2.8052000999450684, -2.801500082015991, -4.188600063323975, -4.188700199127197, -4.188700199127197, -4.188700199127197, -4.188700199127197, -4.188700199127197, -4.189000129699707, -4.189000129699707, -4.189000129699707, -4.189000129699707, -4.189000129699707, -4.189000129699707, -4.188399791717529, -4.188399791717529, -4.188399791717529, -4.188399791717529, -4.188499927520752, -4.188499927520752, -4.189599990844727, -4.189599990844727, -4.189599990844727, -4.189599990844727, -4.189599990844727, -4.189599990844727, -4.189599990844727, -4.189599990844727, -4.189599990844727, -4.184000015258789, -4.187600135803223, -2.9595999717712402, -2.959700107574463, -2.959700107574463, -3.519200086593628, -3.519200086593628, -3.519200086593628, -3.5192999839782715, -3.5192999839782715, -3.5192999839782715, -3.5192999839782715, -3.5192999839782715, -3.519399881362915, -3.519399881362915, -3.519399881362915, -3.519399881362915, -3.519399881362915, -3.519399881362915, -3.519399881362915, -3.5197999477386475, -3.5197999477386475, -3.5197999477386475, -3.5197999477386475, -3.5197999477386475, -3.51990008354187, -2.600600004196167, -4.9029998779296875, -4.9029998779296875, -4.904099941253662, -4.904200077056885, -4.904200077056885, -4.901299953460693, -4.90339994430542, -2.588099956512451, -3.1468000411987305, -3.1468000411987305, -3.146899938583374, -3.146899938583374, -3.146899938583374, -3.146899938583374, -3.146899938583374, -3.146899938583374, -3.146899938583374, -3.146899938583374, -3.146899938583374, -3.1470000743865967, -3.149199962615967, -3.151400089263916, -4.529900074005127, -4.529900074005127, -4.531499862670898, -4.531499862670898, -4.531499862670898, -4.531499862670898, -4.529600143432617, -4.529699802398682, -4.529799938201904, -4.529799938201904, -4.529900074005127, -4.53000020980835, -4.53000020980835, -4.530099868774414, -4.530099868774414, -4.528200149536133, -4.528800010681152, -4.5289998054504395, -4.530099868774414]}, \"token.table\": {\"Topic\": [2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2], \"Freq\": [1.0890210762948382, 0.8554292787776024, 0.8553239325855992, 0.9951655000837728, 0.9951488245078912, 0.8552944230217712, 1.0890392499308728, 0.6632454040304945, 0.9951644404753489, 1.0890156713362933, 0.9951465404673335, 0.7463821648995551, 0.9951467390426268, 0.9951659620685207, 0.855304072634309, 0.6648889525395818, 0.3324444762697909, 0.8554373829178922, 0.855321178920081, 0.9951648976983795, 0.8553240311637356, 0.8553039039195321, 0.8554454965125158, 0.855309914351299, 0.855430693722782, 0.9951436244452677, 0.8553267637500227, 0.9951665224001336, 0.855315153773342, 0.9951456551655199, 0.855283053512956, 0.855326309403141, 0.8553097507718641, 0.8554351506760444, 0.9951473112011532, 0.8553097877374275, 0.8554272848628036, 0.8553194939157168, 0.9951655660730727, 0.8552922589223073], \"Term\": [\"allow\", \"awarnes\", \"bring\", \"chance\", \"decent\", \"depth\", \"emotion\", \"entertainment\", \"escape\", \"experience\", \"fiction\", \"forget\", \"general\", \"hours\", \"hurting\", \"movie\", \"movie\", \"movie.all\", \"never\", \"offer\", \"opportunity\", \"otherwise\", \"people\", \"period\", \"please\", \"provide\", \"range\", \"responsibility\", \"richness\", \"science\", \"screen\", \"short\", \"situation\", \"socity\", \"think\", \"variety\", \"watch\", \"without\", \"worry\", \"would\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el560017477412459923728035681\", ldavis_el560017477412459923728035681_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el560017477412459923728035681\", ldavis_el560017477412459923728035681_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el560017477412459923728035681\", ldavis_el560017477412459923728035681_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model3_2.gensim')\n",
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, it can be seen that the three topics extracted from the reponses are about the equal size. The first topic can be recognized as hedonic experience, as the top words in the topic are \"reduce stress\" and \"improve happiness\". The second topic can be seen as social experiecne, as there are words like \"people\", \"discuss idea\" in the second topic. The third topic can be treated as eudaimonic experience, as there are words like \"insight\", and \"problem\" in the topic. The differences and distinction between these three topics are not very obvious, probably due to the relative small sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion and Summary\n",
    "The present project utilizes the LDA method to solicit topics from two corpuses. The first part uses LDA method to elicit topics from textual responses. The second and third part uses LDA method and improves the topic modeling on two different textual responses. The results showed that LDA has great potential in recognizing and differntiating different topics. This technique can be applied in various social scientific studies in the future and help scholars understand textual responses better.\n",
    "\n",
    "## Results\n",
    "The topic modeling results have significant implications for entertaiment studies. The first topic modeling shows that two topics are prominent when people answering the question about video game function in families. People genreally believe that video games help families unite and they get a lot of fun through video games. However, when people answer the same question regarding movies, they also mention insights, inspirations, and other eudaimonic functions of movies. It seems movies have more functions than video games but when we looked deeper at the reponses about video games, we also see responses like \"learning\" and \"coorperation\" in the corpus. The eudaimonic topic is not prominent but still exists. So far, it is probably safe to say that ,in genreal, entertainment has roughly three functions in people's life:  \n",
    "1) Hedonic, people look for fun in entertainment, and seek escapism, diversion, and relaxation.  \n",
    "2) Eudaimonism, people seek meanings and personal grwoth in entertainment. They learn to grow and look for inspirations and insights in entertainment contents.  \n",
    "3) Social, people see entertainment as a social venue and look for relatedness with other people when consuming entertainment content.  \n",
    "\n",
    "## Limitations\n",
    "The present project is not without limitations.  \n",
    "First, the results of the topic modeling are not stable. Different iterations usually provides different resutls, and an ideal result needs multiple trials. It is probably due to the small descrepancies between different topics and responses.  \n",
    "Second, the differences between topics are not very obvious. It still needs very careful human inspection, or even expert inspection to understand and label the different topics. It is probably because it is unguided machine learning, there are no guidelines on how the machine can learn the topics, but also due to the small sample size. If we can increase the sample size to about 1000, I believe the results can be a lot more stable and differentiable.  \n",
    "\n",
    "## Summary\n",
    "Overall, the present project utilizes machine learnign strategy to traditional social scientific studies. Using natural human textual responses, with the help of LDA machine learning, researchers can achieve a lot more than traditional human coding. The result of three topics can inspire a lot more other studies in this area and future research can also utilize this machine learning technique to understand other textual responses in other social scientific areas of interest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
